---
title: "Response metadata"
---

Many model providers include some metadata in their chat generation [responses](/src/oss/concepts/messages/#aimessage). This metadata can be accessed via the `AIMessage.response_metadata: Dict` attribute. Depending on the model provider and model configuration, this can contain information like [token counts](/src/oss/how_to/chat_token_usage_tracking), [logprobs](/src/oss/how_to/logprobs), and more.

Here's what the response metadata looks like for a few different providers:

## OpenAI

```
from langchain_openai import ChatOpenAIllm = ChatOpenAI(model="gpt-4o-mini")msg = llm.invoke("What's the oldest known example of cuneiform")msg.response_metadata
```

**API Reference:**[ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)

```
{'token_usage': {'completion_tokens': 110,  'prompt_tokens': 16,  'total_tokens': 126,  'completion_tokens_details': {'accepted_prediction_tokens': 0,   'audio_tokens': 0,   'reasoning_tokens': 0,   'rejected_prediction_tokens': 0},  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'id': 'chatcmpl-BDrISvLar6AqcZngBmhajFZXVc2u9', 'finish_reason': 'stop', 'logprobs': None}
```

## Anthropic

```
from langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model="claude-3-5-sonnet-latest")msg = llm.invoke("What's the oldest known example of cuneiform")msg.response_metadata
```

**API Reference:**[ChatAnthropic](https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html)

```
{'id': 'msg_01JHnvPqgERY7MZwrvfkmq52', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0,  'cache_read_input_tokens': 0,  'input_tokens': 17,  'output_tokens': 221}, 'model_name': 'claude-3-5-sonnet-20241022'}
```

## Google VertexAI

```
from langchain_google_vertexai import ChatVertexAIllm = ChatVertexAI(model="gemini-2.0-flash-001")msg = llm.invoke("What's the oldest known example of cuneiform")msg.response_metadata
```

**API Reference:**[ChatVertexAI](https://python.langchain.com/api_reference/google_vertexai/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html)

```
{'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 10,  'candidates_token_count': 55,  'total_token_count': 65,  'prompt_tokens_details': [{'modality': 1, 'token_count': 10}],  'candidates_tokens_details': [{'modality': 1, 'token_count': 55}],  'cached_content_token_count': 0,  'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.251378042047674, 'model_name': 'gemini-2.0-flash-001'}
```

## Bedrock (Anthropic)")

```
from langchain_aws import ChatBedrockConversellm = ChatBedrockConverse(model="anthropic.claude-3-sonnet-20240229-v1:0")msg = llm.invoke("What's the oldest known example of cuneiform")msg.response_metadata
```

**API Reference:**[ChatBedrockConverse](https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html)

```
{'ResponseMetadata': {'RequestId': 'ea0ac2ad-3ad5-4a49-9647-274a0c73ac31',  'HTTPStatusCode': 200,  'HTTPHeaders': {'date': 'Sat, 22 Mar 2025 11:27:46 GMT',   'content-type': 'application/json',   'content-length': '1660',   'connection': 'keep-alive',   'x-amzn-requestid': 'ea0ac2ad-3ad5-4a49-9647-274a0c73ac31'},  'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [11044]}}
```

## MistralAI

```
from langchain_mistralai import ChatMistralAIllm = ChatMistralAI(model="mistral-small-latest")msg = llm.invoke([("human", "What's the oldest known example of cuneiform")])msg.response_metadata
```

**API Reference:**[ChatMistralAI](https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html)

```
{'token_usage': {'prompt_tokens': 13,  'total_tokens': 219,  'completion_tokens': 206}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop'}
```

## Groq

```
from langchain_groq import ChatGroqllm = ChatGroq(model="llama-3.1-8b-instant")msg = llm.invoke("What's the oldest known example of cuneiform")msg.response_metadata
```

**API Reference:**[ChatGroq](https://python.langchain.com/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html)

```
{'token_usage': {'completion_tokens': 184,  'prompt_tokens': 45,  'total_tokens': 229,  'completion_time': 0.245333333,  'prompt_time': 0.002262803,  'queue_time': 0.19315161,  'total_time': 0.247596136}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a56f6eea01', 'finish_reason': 'stop', 'logprobs': None}
```

## FireworksAI

```
from langchain_fireworks import ChatFireworksllm = ChatFireworks(model="accounts/fireworks/models/llama-v3p1-70b-instruct")msg = llm.invoke("What's the oldest known example of cuneiform")msg.response_metadata
```

**API Reference:**[ChatFireworks](https://python.langchain.com/api_reference/fireworks/chat_models/langchain_fireworks.chat_models.ChatFireworks.html)

```
{'token_usage': {'prompt_tokens': 25,  'total_tokens': 352,  'completion_tokens': 327}, 'model_name': 'accounts/fireworks/models/llama-v3p1-70b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}
```
