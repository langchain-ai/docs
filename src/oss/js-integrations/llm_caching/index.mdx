---
title: Model caches
---

[Caching LLM calls](/oss/how-to/chat_model_caching) can be useful for testing, cost savings, and speed.

Below are some integrations that allow you to cache results of individual LLM calls using different caches with different strategies.

<IndexTable />
