---
title: "ScaNN"
---

ScaNN (Scalable Nearest Neighbors) is a method for efficient vector similarity search at scale.

ScaNN includes search space pruning and quantization for Maximum Inner Product Search and also supports other distance functions such as Euclidean distance. The implementation is optimized for x86 processors with AVX2 support. See its [Google Research github](https://github.com/google-research/google-research/tree/master/scann) for more details.

You'll need to install `langchain-community` with `pip install -qU langchain-community` to use this integration

## Installation

Install ScaNN through pip. Alternatively, you can follow instructions on the [ScaNN Website](https://github.com/google-research/google-research/tree/master/scann#building-from-source) to install from source.

```
%pip install --upgrade --quiet  scann
```

## Retrieval Demo

Below we show how to use ScaNN in conjunction with Huggingface Embeddings.

```
from langchain_community.document_loaders import TextLoaderfrom langchain_community.vectorstores import ScaNNfrom langchain_huggingface import HuggingFaceEmbeddingsfrom langchain_text_splitters import CharacterTextSplitterloader = TextLoader("state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)model_name = "sentence-transformers/all-mpnet-base-v2"embeddings = HuggingFaceEmbeddings(model_name=model_name)db = ScaNN.from_documents(docs, embeddings)query = "What did the president say about Ketanji Brown Jackson"docs = db.similarity_search(query)docs[0]
```

**API Reference:**[TextLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.text.TextLoader.html) | [ScaNN](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.scann.ScaNN.html) | [HuggingFaceEmbeddings](https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html) | [CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html)

## RetrievalQA Demo

Next, we demonstrate using ScaNN in conjunction with Google PaLM API.

You can obtain an API key from [https://developers.generativeai.google/tutorials/setup](https://developers.generativeai.google/tutorials/setup)

```
from langchain.chains import RetrievalQAfrom langchain_community.chat_models.google_palm import ChatGooglePalmpalm_client = ChatGooglePalm(google_api_key="YOUR_GOOGLE_PALM_API_KEY")qa = RetrievalQA.from_chain_type(    llm=palm_client,    chain_type="stuff",    retriever=db.as_retriever(search_kwargs={"k": 10}),)
```

**API Reference:**[RetrievalQA](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html) | [ChatGooglePalm](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.google_palm.ChatGooglePalm.html)

```
print(qa.run("What did the president say about Ketanji Brown Jackson?"))
```

```
The president said that Ketanji Brown Jackson is one of our nation's top legal minds, who will continue Justice Breyer's legacy of excellence.
```

```
print(qa.run("What did the president say about Michael Phelps?"))
```

```
The president did not mention Michael Phelps in his speech.
```

## Save and loading local retrieval index

```
db.save_local("/tmp/db", "state_of_union")restored_db = ScaNN.load_local("/tmp/db", embeddings, index_name="state_of_union")
```

## Related

* Vector store [conceptual guide](/oss/concepts/vectorstores)
* Vector store [how-to guides](/oss/how_to/#vector-stores)
