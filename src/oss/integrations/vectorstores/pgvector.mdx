---
title: "PGVector"
---

> An implementation of LangChain vectorstore abstraction using `postgres` as the backend and utilizing the `pgvector` extension.

The code lives in an integration package called: [langchain\_postgres](https://github.com/langchain-ai/langchain-postgres/).

## Status

This code has been ported over from `langchain_community` into a dedicated package called `langchain-postgres`. The following changes have been made:

* langchain\_postgres works only with psycopg3. Please update your connnecion strings from `postgresql+psycopg2://...` to `postgresql+psycopg://langchain:langchain@...` (yes, it's the driver name is `psycopg` not `psycopg3`, but it'll use `psycopg3`.
* The schema of the embedding store and collection have been changed to make add\_documents work correctly with user specified ids.
* One has to pass an explicit connection object now.

Currently, there is **no mechanism** that supports easy data migration on schema changes. So any schema changes in the vectorstore will require the user to recreate the tables and re-add the documents. If this is a concern, please use a different vectorstore. If not, this implementation should be fine for your use case.

## Setup

First donwload the partner package:

```
pip install -qU langchain_postgres
```

You can run the following command to spin up a a postgres container with the `pgvector` extension:

```
%docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16
```

### Credentials

There are no credentials needed to run this notebook, just make sure you downloaded the `langchain_postgres` package and correctly started the postgres container.

If you want to get best in-class automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:

```
# os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")# os.environ["LANGSMITH_TRACING"] = "true"
```

## Instantiation

Select [embeddings model](/src/oss/integrations/text_embedding):

OpenAIâ–¾

* [OpenAI](#)

* [Azure](#)

* [Google Gemini](#)

* [Google Vertex](#)

* [AWS](#)

* [HuggingFace](#)

* [Ollama](#)

* [Cohere](#)

* [MistralAI](#)

* [Nomic](#)

* [NVIDIA](#)

* [Voyage AI](#)

* [IBM watsonx](#)

* [Fake](#)

```
pip install -qU langchain-openai
```

```
import getpassimport osif not os.environ.get("OPENAI_API_KEY"):  os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter API key for OpenAI: ")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model="text-embedding-3-large")
```

```
from langchain_postgres import PGVector# See docker command above to launch a postgres instance with pgvector enabled.connection = "postgresql+psycopg://langchain:langchain@localhost:6024/langchain"  # Uses psycopg3!collection_name = "my_docs"vector_store = PGVector(    embeddings=embeddings,    collection_name=collection_name,    connection=connection,    use_jsonb=True,)
```

## Manage vector store

### Add items to vector store

Note that adding documents by ID will over-write any existing documents that match that ID.

```
from langchain_core.documents import Documentdocs = [    Document(        page_content="there are cats in the pond",        metadata={"id": 1, "location": "pond", "topic": "animals"},    ),    Document(        page_content="ducks are also found in the pond",        metadata={"id": 2, "location": "pond", "topic": "animals"},    ),    Document(        page_content="fresh apples are available at the market",        metadata={"id": 3, "location": "market", "topic": "food"},    ),    Document(        page_content="the market also sells fresh oranges",        metadata={"id": 4, "location": "market", "topic": "food"},    ),    Document(        page_content="the new art exhibit is fascinating",        metadata={"id": 5, "location": "museum", "topic": "art"},    ),    Document(        page_content="a sculpture exhibit is also at the museum",        metadata={"id": 6, "location": "museum", "topic": "art"},    ),    Document(        page_content="a new coffee shop opened on Main Street",        metadata={"id": 7, "location": "Main Street", "topic": "food"},    ),    Document(        page_content="the book club meets at the library",        metadata={"id": 8, "location": "library", "topic": "reading"},    ),    Document(        page_content="the library hosts a weekly story time for kids",        metadata={"id": 9, "location": "library", "topic": "reading"},    ),    Document(        page_content="a cooking class for beginners is offered at the community center",        metadata={"id": 10, "location": "community center", "topic": "classes"},    ),]vector_store.add_documents(docs, ids=[doc.metadata["id"] for doc in docs])
```

**API Reference:**[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)

```
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
```

### Delete items from vector store

```
vector_store.delete(ids=["3"])
```

## Query vector store

Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.

### Filtering Support

The vectorstore supports a set of filters that can be applied against the metadata fields of the documents.

| Operator | Meaning/Category             |
| -------- | ---------------------------- |
| $eq      | Equality (==)                |
| $ne      | Inequality (!=)              |
| $lt      | Less than (\<)               |
| $lte     | Less than or equal (\<=)     |
| $gt      | Greater than (>)             |
| $gte     | Greater than or equal (>=)   |
| $in      | Special Cased (in)           |
| $nin     | Special Cased (not in)       |
| $between | Special Cased (between)      |
| $like    | Text (like)                  |
| $ilike   | Text (case-insensitive like) |
| $and     | Logical (and)                |
| $or      | Logical (or)                 |

### Query directly

Performing a simple similarity search can be done as follows:

```
results = vector_store.similarity_search(    "kitty", k=10, filter={"id": {"$in": [1, 5, 2, 9]}})for doc in results:    print(f"* {doc.page_content} [{doc.metadata}]")
```

```
* there are cats in the pond [{'id': 1, 'topic': 'animals', 'location': 'pond'}]* the library hosts a weekly story time for kids [{'id': 9, 'topic': 'reading', 'location': 'library'}]* ducks are also found in the pond [{'id': 2, 'topic': 'animals', 'location': 'pond'}]* the new art exhibit is fascinating [{'id': 5, 'topic': 'art', 'location': 'museum'}]
```

If you provide a dict with multiple fields, but no operators, the top level will be interpreted as a logical **AND** filter

```
vector_store.similarity_search(    "ducks",    k=10,    filter={"id": {"$in": [1, 5, 2, 9]}, "location": {"$in": ["pond", "market"]}},)
```

```
[Document(metadata={'id': 1, 'topic': 'animals', 'location': 'pond'}, page_content='there are cats in the pond'), Document(metadata={'id': 2, 'topic': 'animals', 'location': 'pond'}, page_content='ducks are also found in the pond')]
```

```
vector_store.similarity_search(    "ducks",    k=10,    filter={        "$and": [            {"id": {"$in": [1, 5, 2, 9]}},            {"location": {"$in": ["pond", "market"]}},        ]    },)
```

```
[Document(metadata={'id': 1, 'topic': 'animals', 'location': 'pond'}, page_content='there are cats in the pond'), Document(metadata={'id': 2, 'topic': 'animals', 'location': 'pond'}, page_content='ducks are also found in the pond')]
```

If you want to execute a similarity search and receive the corresponding scores you can run:

```
results = vector_store.similarity_search_with_score(query="cats", k=1)for doc, score in results:    print(f"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]")
```

```
* [SIM=0.763449] there are cats in the pond [{'id': 1, 'topic': 'animals', 'location': 'pond'}]
```

For a full list of the different searches you can execute on a `PGVector` vector store, please refer to the [API reference](https://python.langchain.com/api_reference/postgres/vectorstores/langchain_postgres.vectorstores.PGVector.html).

### Query by turning into retriever

You can also transform the vector store into a retriever for easier usage in your chains.

```
retriever = vector_store.as_retriever(search_type="mmr", search_kwargs={"k": 1})retriever.invoke("kitty")
```

```
[Document(metadata={'id': 1, 'topic': 'animals', 'location': 'pond'}, page_content='there are cats in the pond')]
```

## Usage for retrieval-augmented generation

For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:

* [Tutorials](/src/oss/tutorials)
* [How-to: Question and answer with RAG](https://python.langchain.com/oss/how_to/#qa-with-rag)
* [Retrieval conceptual docs](https://python.langchain.com/oss/concepts/retrieval)

## API reference

For detailed documentation of all \_\_ModuleName\_\_VectorStore features and configurations head to the API reference: [https://python.langchain.com/api\_reference/postgres/vectorstores/langchain\_postgres.vectorstores.PGVector.html](https://python.langchain.com/api_reference/postgres/vectorstores/langchain_postgres.vectorstores.PGVector.html)

## Related

* Vector store [conceptual guide](/src/oss/concepts/vectorstores)
* Vector store [how-to guides](/src/oss/how_to/#vector-stores)
