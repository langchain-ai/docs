---
title: "CogneeRetriever"
---

This will help you get started with the Cognee [retriever](/oss/concepts/retrievers). For detailed documentation of all CogneeRetriever features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.cognee.CogneeRetriever.html).

### Integration details

Bring-your-own data (i.e., index and search a custom corpus of documents):

| Retriever                                                                                                                                     | Self-host | Cloud offering | Package          |
| --------------------------------------------------------------------------------------------------------------------------------------------- | --------- | -------------- | ---------------- |
| [CogneeRetriever](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.cognee.CogneeRetriever.html) | ✅         | ❌              | langchain-cognee |

## Setup

For cognee default setup, only thing you need is your OpenAI API key.

If you want to get automated tracing from individual queries, you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:

```
# os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")# os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

This retriever lives in the `langchain-cognee` package:

```
%pip install -qU langchain-cognee
```

```
import nest_asyncionest_asyncio.apply()
```

## Instantiation

Now we can instantiate our retriever:

```
from langchain_cognee import CogneeRetrieverretriever = CogneeRetriever(    llm_api_key="sk-",  # OpenAI API Key    dataset_name="my_dataset",    k=3,)
```

## Usage

Add some documents, process them, and then run queries. Cognee retrieves relevant knowledge to your queries and generates final answers.

```
# Example of adding and processing documentsfrom langchain_core.documents import Documentdocs = [    Document(page_content="Elon Musk is the CEO of SpaceX."),    Document(page_content="SpaceX focuses on rockets and space travel."),]retriever.add_documents(docs)retriever.process_data()# Now let's query the retrieverquery = "Tell me about Elon Musk"results = retriever.invoke(query)for idx, doc in enumerate(results, start=1):    print(f"Doc {idx}: {doc.page_content}")
```

**API Reference:**[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)

## Use within a chain

Like other retrievers, CogneeRetriever can be incorporated into LLM applications via [chains](/oss/how_to/sequence).

We will need a LLM or chat model:

Select [chat model](/oss/integrations/chat):

Google Gemini▾

* [OpenAI](/oss/integrations/text_embedding/openai)

* [Anthropic](/oss/integrations/text_embedding/bedrock)

* [Azure](/oss/integrations/text_embedding/azureopenai)

* [Google Gemini](/oss/integrations/text_embedding/google_generative_ai)

* [Google Vertex](/oss/integrations/text_embedding/google_vertex_ai_palm)

* [AWS](/oss/integrations/text_embedding/bedrock)

* [Groq](/oss/integrations/text_embedding/groq)

* [Cohere](/oss/integrations/text_embedding/cohere)

* [NVIDIA](/oss/integrations/text_embedding/nvidia_ai_endpoints)

* [Fireworks AI](/oss/integrations/text_embedding/fireworks)

* [Mistral AI](/oss/integrations/text_embedding/mistralai)

* [Together AI](/oss/integrations/text_embedding/together)

* [IBM watsonx](/oss/integrations/text_embedding/ibm_watsonx)

* [Databricks](/oss/integrations/text_embedding/databricks)

* [xAI](/oss/integrations/text_embedding/xai)

* [Perplexity](/oss/integrations/text_embedding/perplexity)

```
pip install -qU "langchain[google-genai]"
```

```
import getpassimport osif not os.environ.get("GOOGLE_API_KEY"):  os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter API key for Google Gemini: ")from langchain.chat_models import init_chat_modelllm = init_chat_model("gemini-2.0-flash", model_provider="google_genai")
```

```
from langchain_openai import ChatOpenAIllm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
```

**API Reference:**[ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)

```
from langchain_cognee import CogneeRetrieverfrom langchain_core.documents import Documentfrom langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.runnables import RunnablePassthrough# Instantiate the retriever with your Cognee configretriever = CogneeRetriever(llm_api_key="sk-", dataset_name="my_dataset", k=3)# Optionally, prune/reset the dataset for a clean slateretriever.prune()# Add some documentsdocs = [    Document(page_content="Elon Musk is the CEO of SpaceX."),    Document(page_content="SpaceX focuses on space travel."),]retriever.add_documents(docs)retriever.process_data()prompt = ChatPromptTemplate.from_template(    """Answer the question based only on the context provided.Context: {context}Question: {question}""")def format_docs(docs):    return "\n\n".join(doc.page_content for doc in docs)chain = (    {"context": retriever | format_docs, "question": RunnablePassthrough()}    | prompt    | llm    | StrOutputParser())
```

**API Reference:**[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) | [StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [RunnablePassthrough](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)

```
answer = chain.invoke("What companies do Elon Musk own?")print("\nFinal chain answer:\n", answer)
```

## API reference

TODO: add link to API reference.

## Related

* Retriever [conceptual guide](/oss/concepts/retrievers)
* Retriever [how-to guides](/oss/how_to/#retrievers)
