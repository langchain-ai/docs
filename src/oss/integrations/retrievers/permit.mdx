---
title: "PermitRetriever"
---

Permit is an access control platform that provides fine-grained, real-time permission management using various models such as RBAC, ABAC, and ReBAC. It enables organizations to enforce dynamic policies across their applications, ensuring that only authorized users can access specific resources.

### Integration details

This notebook illustrates how to integrate [Permit.io](https://permit.io/) permissions into LangChain retrievers.

We provide two custom retrievers:

* PermitSelfQueryRetriever – Uses a self-query approach to parse the user’s natural-language prompt, fetch the user’s permitted resource IDs from Permit, and apply that filter automatically in a vector store search.

* PermitEnsembleRetriever – Combines multiple underlying retrievers (e.g., BM25 + Vector) via LangChain’s EnsembleRetriever, then filters the merged results with Permit.io.

## Setup

Install the package with the command:

```
pip install langchain-permit
```

If you want to get automated tracing from individual queries, you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:

```
# os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")# os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

```
pip install langchain-permit
```

#### Environment Variables

```
PERMIT_API_KEY=your_api_keyPERMIT_PDP_URL= # or your real deploymentOPENAI_API_KEY=sk-...
```

* A running Permit PDP. See [Permit docs](https://docs.permit.io/) for details on setting up your policy and container.
* A vector store or multiple retrievers that we can wrap.

```
%pip install -qU langchain-permit
```

## Instantiation

### PermitSelfQueryRetriever

#### Basic Explanation

1. Retrieves permitted document IDs from Permit.

2. Uses an LLM to parse your query and build a “structured filter,” ensuring only docs with those permitted IDs are considered.

#### Basic Usage

```
from langchain_openai import OpenAIEmbeddingsfrom langchain_community.vectorstores import FAISSfrom langchain_permit.retrievers import PermitSelfQueryRetriever# Step 1: Create / load some documents and build a vector storedocs = [...]embeddings = OpenAIEmbeddings()vectorstore = FAISS.from_documents(docs, embeddings)# Step 2: Initialize the retrieverretriever = PermitSelfQueryRetriever(    api_key="...",    pdp_url="...",    user={"key": "user-123"},    resource_type="document",    action="read",    llm=...,                # Typically a ChatOpenAI or other LLM    vectorstore=vectorstore,    enable_limit=True,      # optional)# Step 3: Queryquery = "Give me docs about cats"results = retriever.get_relevant_documents(query)for doc in results:    print(doc.metadata.get("id"), doc.page_content)
```

**API Reference:**[OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html) | [FAISS](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html)

### PermitEnsembleRetriever

#### Basic Explanation

1. Uses LangChain’s EnsembleRetriever to gather documents from multiple sub-retrievers (e.g., vector-based, BM25, etc.).
2. After retrieving documents, it calls filter\_objects on Permit to eliminate any docs the user isn’t allowed to see.

#### Basic Usage

```
from langchain_community.retrievers import BM25Retrieverfrom langchain_core.documents import Documentfrom langchain_permit.retrievers import PermitEnsembleRetriever# Suppose we have two child retrievers: bm25_retriever, vector_retriever...ensemble_retriever = PermitEnsembleRetriever(    api_key="...",    pdp_url="...",    user="user_abc",    action="read",    resource_type="document",    retrievers=[bm25_retriever, vector_retriever],    weights=None)docs = ensemble_retriever.get_relevant_documents("Query about cats")for doc in docs:    print(doc.metadata.get("id"), doc.page_content)
```

**API Reference:**[BM25Retriever](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.bm25.BM25Retriever.html) | [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)

### Demo Scripts

For more complete demos, check out the `/langchain_permit/examples/demo_scripts` folder:

1. demo\_self\_query.py – Demonstrates PermitSelfQueryRetriever.
2. demo\_ensemble.py – Demonstrates PermitEnsembleRetriever.

Each script shows how to build or load documents, configure Permit, and run queries.

### Conclusion

With these custom retrievers, you can seamlessly integrate Permit.io’s permission checks into LangChain’s retrieval workflow. You can keep your application’s vector search logic while ensuring only authorized documents are returned.

For more details on setting up Permit policies, see the official Permit docs. If you want to combine these with other tools (like JWT validation or a broader RAG pipeline), check out our docs/tools.ipynb in the examples folder.

```
from langchain_permit import PermitRetrieverretriever = PermitRetriever(    # ...)
```

## Usage

```
query = "..."retriever.invoke(query)
```

## Use within a chain

Like other retrievers, PermitRetriever can be incorporated into LLM applications via [chains](https://docs.permit.io/).

We will need a LLM or chat model:

Select [chat model](/oss/integrations/chat):

Google Gemini▾

* [OpenAI](/oss/integrations/text_embedding/openai)

* [Anthropic](/oss/integrations/text_embedding/bedrock)

* [Azure](/oss/integrations/text_embedding/azureopenai)

* [Google Gemini](/oss/integrations/text_embedding/google_generative_ai)

* [Google Vertex](/oss/integrations/text_embedding/google_vertex_ai_palm)

* [AWS](/oss/integrations/text_embedding/bedrock)

* [Groq](/oss/integrations/text_embedding/groq)

* [Cohere](/oss/integrations/text_embedding/cohere)

* [NVIDIA](/oss/integrations/text_embedding/nvidia_ai_endpoints)

* [Fireworks AI](/oss/integrations/text_embedding/fireworks)

* [Mistral AI](/oss/integrations/text_embedding/mistralai)

* [Together AI](/oss/integrations/text_embedding/together)

* [IBM watsonx](/oss/integrations/text_embedding/ibm_watsonx)

* [Databricks](/oss/integrations/text_embedding/databricks)

* [xAI](/oss/integrations/text_embedding/xai)

* [Perplexity](/oss/integrations/text_embedding/perplexity)

```
pip install -qU "langchain[google-genai]"
```

```
import getpassimport osif not os.environ.get("GOOGLE_API_KEY"):  os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter API key for Google Gemini: ")from langchain.chat_models import init_chat_modelllm = init_chat_model("gemini-2.0-flash", model_provider="google_genai")
```

```
from langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.runnables import RunnablePassthroughprompt = ChatPromptTemplate.from_template(    """Answer the question based only on the context provided.Context: {context}Question: {question}""")def format_docs(docs):    return "\n\n".join(doc.page_content for doc in docs)chain = (    {"context": retriever | format_docs, "question": RunnablePassthrough()}    | prompt    | llm    | StrOutputParser())
```

**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [RunnablePassthrough](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)

```
chain.invoke("...")
```

## API reference

For detailed documentation of all PermitRetriever features and configurations head to the [Repo](https://github.com/permitio/langchain-permit/tree/master/langchain_permit/examples/demo_scripts).

## Related

* Retriever [conceptual guide](/oss/concepts/retrievers)
* Retriever [how-to guides](/oss/how_to/#retrievers)
