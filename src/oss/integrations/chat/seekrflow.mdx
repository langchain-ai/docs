---
title: "ChatSeekrFlow"
---

> [Seekr](https://www.seekr.com/) provides AI-powered solutions for structured, explainable, and transparent AI interactions.

This notebook provides a quick overview for getting started with Seekr [chat models](/oss/concepts/chat_models). For detailed documentation of all `ChatSeekrFlow` features and configurations, head to the [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html).

## Overview

`ChatSeekrFlow` class wraps a chat model endpoint hosted on SeekrFlow, enabling seamless integration with LangChain applications.

### Integration Details

| Class                                                                                                                                          | Package                                                                    | Local | Serializable | Package downloads                                                             | Package latest                                                             |
| ---------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- | ----- | ------------ | ----------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| [ChatSeekrFlow](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html) | [seekrai](https://python.langchain.com/oss/integrations/providers/seekr/) | ‚ùå     | beta         | ![PyPI - Downloads](/images/oss/integrations/chat/seekrflow/pypi/dm/seekrai) | ![PyPI - Version](/images/oss/integrations/chat/seekrflow/pypi/v/seekrai) |

### Model Features

| [Tool calling](/oss/how_to/tool_calling) | [Structured output](/oss/how_to/structured_output) | JSON mode | [Image input](/oss/how_to/multimodal_inputs) | Audio input | Video input | [Token-level streaming](/oss/how_to/chat_streaming) | Native async | [Token usage](/oss/how_to/chat_token_usage_tracking) | [Logprobs](/oss/how_to/logprobs) |
| ------------------------------------------ | ---------------------------------------------------- | --------- | ---------------------------------------------- | ----------- | ----------- | ----------------------------------------------------- | ------------ | ------------------------------------------------------ | ---------------------------------- |
| ‚úÖ                                          | ‚úÖ                                                    | ‚úÖ         | ‚ùå                                              | ‚ùå           | ‚ùå           | ‚úÖ                                                     | ‚ùå            | ‚úÖ                                                      | ‚ùå                                  |

### Supported Methods

`ChatSeekrFlow` supports all methods of `ChatModel`, **except async APIs**.

### Endpoint Requirements

The serving endpoint `ChatSeekrFlow` wraps **must** have OpenAI-compatible chat input/output format. It can be used for:

1. **Fine-tuned Seekr models**
2. **Custom SeekrFlow models**
3. **RAG-enabled models using Seekr's retrieval system**

For async usage, please refer to `AsyncChatSeekrFlow` (coming soon).

# Getting Started with ChatSeekrFlow in LangChain

This notebook covers how to use SeekrFlow as a chat model in LangChain.

## Setup

Ensure you have the necessary dependencies installed:

```
pip install seekrai langchain langchain-community
```

You must also have an API key from Seekr to authenticate requests.

```
# Standard libraryimport getpassimport os# Third-partyfrom langchain.prompts import ChatPromptTemplatefrom langchain.schema import HumanMessagefrom langchain_core.runnables import RunnableSequence# OSS SeekrFlow integrationfrom langchain_seekrflow import ChatSeekrFlowfrom seekrai import SeekrFlow
```

**API Reference:**[ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [HumanMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) | [RunnableSequence](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableSequence.html)

## API Key Setup

You'll need to set your API key as an environment variable to authenticate requests.

Run the below cell.

Or manually assign it before running queries:

```
SEEKR_API_KEY = "your-api-key-here"
```

```
os.environ["SEEKR_API_KEY"] = getpass.getpass("Enter your Seekr API key:")
```

## Instantiation

```
os.environ["SEEKR_API_KEY"]seekr_client = SeekrFlow(api_key=SEEKR_API_KEY)llm = ChatSeekrFlow(    client=seekr_client, model_name="meta-llama/Meta-Llama-3-8B-Instruct")
```

## Invocation

```
response = llm.invoke([HumanMessage(content="Hello, Seekr!")])print(response.content)
```

```
Hello there! I'm Seekr, nice to meet you! What brings you here today? Do you have a question, or are you looking for some help with something? I'm all ears (or rather, all text)!
```

## Chaining

```
prompt = ChatPromptTemplate.from_template("Translate to French: {text}")chain: RunnableSequence = prompt | llmresult = chain.invoke({"text": "Good morning"})print(result)
```

```
content='The translation of "Good morning" in French is:\n\n"Bonne journ√©e"' additional_kwargs={} response_metadata={}
```

```
def test_stream():    """Test synchronous invocation in streaming mode."""    print("\nüîπ Testing Sync `stream()` (Streaming)...")    for chunk in llm.stream([HumanMessage(content="Write me a haiku.")]):        print(chunk.content, end="", flush=True)# ‚úÖ Ensure streaming is enabledllm = ChatSeekrFlow(    client=seekr_client,    model_name="meta-llama/Meta-Llama-3-8B-Instruct",    streaming=True,  # ‚úÖ Enable streaming)# ‚úÖ Run sync streaming testtest_stream()
```

```
üîπ Testing Sync `stream()` (Streaming)...Here is a haiku:Golden sunset fadesRipples on the quiet lakePeaceful evening sky
```

## Error Handling & Debugging

```
# Define a minimal mock SeekrFlow clientclass MockSeekrClient:    """Mock SeekrFlow API client that mimics the real API structure."""    class MockChat:        """Mock Chat object with a completions method."""        class MockCompletions:            """Mock Completions object with a create method."""            def create(self, *args, **kwargs):                return {                    "choices": [{"message": {"content": "Mock response"}}]                }  # Mimic API response        completions = MockCompletions()    chat = MockChat()def test_initialization_errors():    """Test that invalid ChatSeekrFlow initializations raise expected errors."""    test_cases = [        {            "name": "Missing Client",            "args": {"client": None, "model_name": "seekrflow-model"},            "expected_error": "SeekrFlow client cannot be None.",        },        {            "name": "Missing Model Name",            "args": {"client": MockSeekrClient(), "model_name": ""},            "expected_error": "A valid model name must be provided.",        },    ]    for test in test_cases:        try:            print(f"Running test: {test['name']}")            faulty_llm = ChatSeekrFlow(**test["args"])            # If no error is raised, fail the test            print(f"‚ùå Test '{test['name']}' failed: No error was raised!")        except Exception as e:            error_msg = str(e)            assert test["expected_error"] in error_msg, f"Unexpected error: {error_msg}"            print(f"‚úÖ Expected Error: {error_msg}")# Run testtest_initialization_errors()
```

```
Running test: Missing Client‚úÖ Expected Error: SeekrFlow client cannot be None.Running test: Missing Model Name‚úÖ Expected Error: A valid model name must be provided.
```

## API reference

* `ChatSeekrFlow` class: [`langchain_seekrflow.ChatSeekrFlow`](https://github.com/benfaircloth/langchain-seekrflow/blob/main/langchain_seekrflow/seekrflow.py)
* PyPI package: [`langchain-seekrflow`](https://pypi.org/project/langchain-seekrflow/)

## Related

* Chat model [conceptual guide](/oss/concepts/chat_models)
* Chat model [how-to guides](/oss/how_to/#chat-models)
