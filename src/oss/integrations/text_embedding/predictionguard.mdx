---
title: "PredictionGuardEmbeddings"
---

> [Prediction Guard](https://predictionguard.com) is a secure, scalable GenAI platform that safeguards sensitive data, prevents common AI malfunctions, and runs on affordable hardware.

## Overview

### Integration details

This integration shows how to use the Prediction Guard embeddings integration with Langchain. This integration supports text and images, separately or together in matched pairs.

## Setup

To access Prediction Guard models, contact us [here](https://predictionguard.com/get-started) to get a Prediction Guard API key and get started.

### Credentials

Once you have a key, you can set it with

```
import osos.environ["PREDICTIONGUARD_API_KEY"] = "<Prediction Guard API Key"
```

### Installation

```
%pip install --upgrade --quiet langchain-predictionguard
```

## Instantiation

First, install the Prediction Guard and LangChain packages. Then, set the required env vars and set up package imports.

```
from langchain_predictionguard import PredictionGuardEmbeddings
```

```
embeddings = PredictionGuardEmbeddings(model="bridgetower-large-itm-mlm-itc")
```

Prediction Guard embeddings generation supports both text and images. This integration includes that support spread across various functions.

## Indexing and Retrieval

```
# Create a vector store with a sample textfrom langchain_core.vectorstores import InMemoryVectorStoretext = "LangChain is the framework for building context-aware reasoning applications."vectorstore = InMemoryVectorStore.from_texts(    [text],    embedding=embeddings,)# Use the vectorstore as a retrieverretriever = vectorstore.as_retriever()# Retrieve the most similar textretrieved_documents = retriever.invoke("What is LangChain?")# Show the retrieved document's contentretrieved_documents[0].page_content
```

**API Reference:**[InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html)

```
'LangChain is the framework for building context-aware reasoning applications.'
```

## Direct Usage

The vectorstore and retriever implementations are calling `embeddings.embed_documents(...)` and `embeddings.embed_query(...)` to create embeddings from the texts used in the `from_texts` and retrieval `invoke` operations.

These methods can be directly called with the following commands.

### Embed single texts

```
# Embedding a single stringtext = "This is an embedding example."single_vector = embeddings.embed_query(text)single_vector[:5]
```

```
[0.01456777285784483, -0.08131945133209229, -0.013045587576925755, -0.09488929063081741, -0.003087474964559078]
```

### Embed multiple texts

```
# Embedding multiple stringsdocs = [    "This is an embedding example.",    "This is another embedding example.",]two_vectors = embeddings.embed_documents(docs)for vector in two_vectors:    print(vector[:5])
```

```
[0.01456777285784483, -0.08131945133209229, -0.013045587576925755, -0.09488929063081741, -0.003087474964559078][-0.0015021917643025517, -0.08883760124444962, -0.0025286630261689425, -0.1052245944738388, 0.014225339516997337]
```

### Embed single images

```
# Embedding a single image. These functions accept image URLs, image files, data URIs, and base64 encoded strings.image = [    "https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg",]single_vector = embeddings.embed_images(image)print(single_vector[0][:5])
```

```
[0.0911610797047615, -0.034427884966135025, 0.007927080616354942, -0.03500846028327942, 0.022317267954349518]
```

### Embed multiple images

```
# Embedding multiple imagesimages = [    "https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI",    "https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg",]two_vectors = embeddings.embed_images(images)for vector in two_vectors:    print(vector[:5])
```

```
[0.1593627631664276, -0.03636132553219795, -0.013229663483798504, -0.08789524435997009, 0.062290553003549576][0.0911610797047615, -0.034427884966135025, 0.007927080616354942, -0.03500846028327942, 0.022317267954349518]
```

### Embed single text-image pairs

```
# Embedding a single text-image pairinputs = [    {        "text": "This is an embedding example.",        "image": "https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg",    },]single_vector = embeddings.embed_image_text(inputs)print(single_vector[0][:5])
```

```
[0.0363212488591671, -0.10172265768051147, -0.014760786667466164, -0.046511903405189514, 0.03860781341791153]
```

### Embed multiple text-image pairs

```
# Embedding multiple text-image pairsinputs = [    {        "text": "This is an embedding example.",        "image": "https://fastly.picsum.photos/id/866/200/300.jpg?hmac=rcadCENKh4rD6MAp6V_ma-AyWv641M4iiOpe1RyFHeI",    },    {        "text": "This is another embedding example.",        "image": "https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg",    },]two_vectors = embeddings.embed_image_text(inputs)for vector in two_vectors:    print(vector[:5])
```

```
[0.11867266893386841, -0.05898813530802727, -0.026179173961281776, -0.10747235268354416, 0.07684746384620667][0.026654226705431938, -0.10080841928720474, -0.012732953764498234, -0.04365091398358345, 0.036743905395269394]
```

## API Reference

For detailed documentation of all PredictionGuardEmbeddings features and configurations check out the API reference: [https://python.langchain.com/api\_reference/community/embeddings/langchain\_community.embeddings.predictionguard.PredictionGuardEmbeddings.html](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.predictionguard.PredictionGuardEmbeddings.html)

## Related

* Embedding model [conceptual guide](/src/oss/concepts/embedding_models)
* Embedding model [how-to guides](/src/oss/how_to/#embedding-models)
