---
title: "Llama.cpp"
---

> [llama.cpp python](https://github.com/abetlen/llama-cpp-python) library is a simple Python bindings for `@ggerganov` [llama.cpp](https://github.com/ggerganov/llama.cpp).
>
> This package provides:
>
> * Low-level access to C API via ctypes interface.
>
> * High-level Python API for text completion
>
>   * `OpenAI`-like API
>   * `LangChain` compatibility
>   * `LlamaIndex` compatibility
>
> * OpenAI compatible web server
>
>   * Local Copilot replacement
>   * Function Calling support
>   * Vision API support
>   * Multiple Models

```
%pip install --upgrade --quiet  llama-cpp-python
```

```
from langchain_community.embeddings import LlamaCppEmbeddings
```

**API Reference:**[LlamaCppEmbeddings](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.llamacpp.LlamaCppEmbeddings.html)

```
llama = LlamaCppEmbeddings(model_path="/path/to/model/ggml-model-q4_0.bin")
```

```
text = "This is a test document."
```

```
query_result = llama.embed_query(text)
```

```
doc_result = llama.embed_documents([text])
```

## Related

* Embedding model [conceptual guide](/oss/concepts/embedding_models)
* Embedding model [how-to guides](/oss/how_to/#embedding-models)
