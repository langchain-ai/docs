---
title: "ModelScope"
---

> [ModelScope](https://www.modelscope.cn/home) is a big repository of the models and datasets.

This page covers how to use the modelscope ecosystem within LangChain. It is broken into two parts: installation and setup, and then references to specific modelscope wrappers.

## Installation

```
pip install -U langchain-modelscope-integration
```

Head to [ModelScope](https://modelscope.cn/) to sign up to ModelScope and generate an [SDK token](https://modelscope.cn/my/myaccesstoken). Once you've done this set the `MODELSCOPE_SDK_TOKEN` environment variable:

```
export MODELSCOPE_SDK_TOKEN=<your_sdk_token>
```

## Chat Models

`ModelScopeChatEndpoint` class exposes chat models from ModelScope. See available models [here](https://www.modelscope.cn/oss/model-service/API-Inference/intro).

```
from langchain_modelscope import ModelScopeChatEndpointllm = ModelScopeChatEndpoint(model="Qwen/Qwen2.5-Coder-32B-Instruct")llm.invoke("Sing a ballad of LangChain.")
```

## Embeddings

`ModelScopeEmbeddings` class exposes embeddings from ModelScope.

```
from langchain_modelscope import ModelScopeEmbeddingsembeddings = ModelScopeEmbeddings(model_id="damo/nlp_corom_sentence-embedding_english-base")embeddings.embed_query("What is the meaning of life?")
```

## LLMs

`ModelScopeLLM` class exposes LLMs from ModelScope.

```
from langchain_modelscope import ModelScopeLLMllm = ModelScopeLLM(model="Qwen/Qwen2.5-Coder-32B-Instruct")llm.invoke("The meaning of life is")
```
