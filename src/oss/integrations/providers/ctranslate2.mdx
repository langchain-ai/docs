---
title: "CTranslate2"
---

> [CTranslate2](https://opennmt.net/CTranslate2/quickstart.html) is a C++ and Python library for efficient inference with Transformer models.
>
> The project implements a custom runtime that applies many performance optimization techniques such as weights quantization, layers fusion, batch reordering, etc., to accelerate and reduce the memory usage of Transformer models on CPU and GPU.
>
> A full list of features and supported models is included in the [projectâ€™s repository](https://opennmt.net/CTranslate2/guides/transformers.html). To start, please check out the official [quickstart guide](https://opennmt.net/CTranslate2/quickstart.html).

## Installation and Setup

Install the Python package:

```
pip install ctranslate2
```

## LLMs

See a [usage example](/src/oss/integrations/llms/ctranslate2).

```
from langchain_community.llms import CTranslate2
```

**API Reference:**[CTranslate2](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.ctranslate2.CTranslate2.html)
