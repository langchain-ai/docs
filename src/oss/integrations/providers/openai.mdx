---
title: "OpenAI"
---

All functionality related to OpenAI

> [OpenAI](https://en.wikipedia.org/wiki/OpenAI) is American artificial intelligence (AI) research laboratory consisting of the non-profit **OpenAI Incorporated** and its for-profit subsidiary corporation **OpenAI Limited Partnership**. **OpenAI** conducts AI research with the declared intention of promoting and developing a friendly AI. **OpenAI** systems run on an **Azure**-based supercomputing platform from **Microsoft**.
>
> The [OpenAI API](https://platform.openai.com/oss/models) is powered by a diverse set of models with different capabilities and price points.
>
> [ChatGPT](https://chat.openai.com) is the Artificial Intelligence (AI) chatbot developed by `OpenAI`.

## Installation and Setup

Install the integration package with

```
pip install langchain-openai
```

Get an OpenAI api key and set it as an environment variable (`OPENAI_API_KEY`)

## Chat model

See a [usage example](/src/oss/integrations/chat/openai).

```
from langchain_openai import ChatOpenAI
```

**API Reference:**[ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)

If you are using a model hosted on `Azure`, you should use different wrapper for that:

```
from langchain_openai import AzureChatOpenAI
```

**API Reference:**[AzureChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html)

For a more detailed walkthrough of the `Azure` wrapper, see [here](/src/oss/integrations/chat/azure_chat_openai).

## LLM

See a [usage example](/src/oss/integrations/llms/openai).

```
from langchain_openai import OpenAI
```

**API Reference:**[OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)

If you are using a model hosted on `Azure`, you should use different wrapper for that:

```
from langchain_openai import AzureOpenAI
```

**API Reference:**[AzureOpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.azure.AzureOpenAI.html)

For a more detailed walkthrough of the `Azure` wrapper, see [here](/src/oss/integrations/llms/azure_openai).

## Embedding Model

See a [usage example](/src/oss/integrations/text_embedding/openai)

```
from langchain_openai import OpenAIEmbeddings
```

**API Reference:**[OpenAIEmbeddings](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html)

## Document Loader

See a [usage example](/src/oss/integrations/document_loaders/chatgpt_loader).

```
from langchain_community.document_loaders.chatgpt import ChatGPTLoader
```

**API Reference:**[ChatGPTLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.chatgpt.ChatGPTLoader.html)

## Retriever

See a [usage example](/src/oss/integrations/retrievers/chatgpt-plugin).

```
from langchain.retrievers import ChatGPTPluginRetriever
```

**API Reference:**[ChatGPTPluginRetriever](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.chatgpt_plugin_retriever.ChatGPTPluginRetriever.html)

## Tools

### Dall-E Image Generator

> [OpenAI Dall-E](https://openai.com/dall-e-3) are text-to-image models developed by `OpenAI` using deep learning methodologies to generate digital images from natural language descriptions, called "prompts".

See a [usage example](/src/oss/integrations/tools/dalle_image_generator).

```
from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper
```

**API Reference:**[DallEAPIWrapper](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.dalle_image_generator.DallEAPIWrapper.html)

## Adapter

See a [usage example](/src/oss/integrations/adapters/openai).

```
from langchain.adapters import openai as lc_openai
```

**API Reference:**[openai](https://python.langchain.com/api_reference/langchain/adapters/langchain.adapters.openai.openai.html)

## Tokenizer

There are several places you can use the `tiktoken` tokenizer. By default, it is used to count tokens for OpenAI LLMs.

You can also use it to count tokens when splitting documents with

```
from langchain.text_splitter import CharacterTextSplitterCharacterTextSplitter.from_tiktoken_encoder(...)
```

**API Reference:**[CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html)

For a more detailed walkthrough of this, see [this notebook](/src/oss/how_to/split_by_token/#tiktoken)

## Chain

See a [usage example](https://python.langchain.com/v0.1/oss/guides/productionization/safety/moderation).

```
from langchain.chains import OpenAIModerationChain
```

**API Reference:**[OpenAIModerationChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.moderation.OpenAIModerationChain.html)
