---
title: "MongoDB Atlas"
---

> [MongoDB Atlas](https://www.mongodb.com/oss/atlas/) is a fully-managed cloud database available in AWS, Azure, and GCP. It now has support for native Vector Search on the MongoDB document data.

## Installation and Setup

See [detail configuration instructions](/oss/integrations/vectorstores/mongodb_atlas).

We need to install `langchain-mongodb` python package.

```
pip install langchain-mongodb
```

## Vector Store

See a [usage example](/oss/integrations/vectorstores/mongodb_atlas).

```
from langchain_mongodb import MongoDBAtlasVectorSearch
```

**API Reference:**[MongoDBAtlasVectorSearch](https://python.langchain.com/api_reference/mongodb/vectorstores/langchain_mongodb.vectorstores.MongoDBAtlasVectorSearch.html)

## Retrievers

### Full Text Search Retriever

> `Hybrid Search Retriever` performs full-text searches using Luceneâ€™s standard (`BM25`) analyzer.

```
from langchain_mongodb.retrievers import MongoDBAtlasFullTextSearchRetriever
```

**API Reference:**[MongoDBAtlasFullTextSearchRetriever](https://python.langchain.com/api_reference/mongodb/retrievers/langchain_mongodb.retrievers.full_text_search.MongoDBAtlasFullTextSearchRetriever.html)

### Hybrid Search Retriever

> `Hybrid Search Retriever` combines vector and full-text searches weighting them the via `Reciprocal Rank Fusion` (`RRF`) algorithm.

```
from langchain_mongodb.retrievers import MongoDBAtlasHybridSearchRetriever
```

**API Reference:**[MongoDBAtlasHybridSearchRetriever](https://python.langchain.com/api_reference/mongodb/retrievers/langchain_mongodb.retrievers.hybrid_search.MongoDBAtlasHybridSearchRetriever.html)

## Model Caches

### MongoDBCache

An abstraction to store a simple cache in MongoDB. This does not use Semantic Caching, nor does it require an index to be made on the collection before generation.

To import this cache:

```
from langchain_mongodb.cache import MongoDBCache
```

**API Reference:**[MongoDBCache](https://python.langchain.com/api_reference/mongodb/cache/langchain_mongodb.cache.MongoDBCache.html)

To use this cache with your LLMs:

```
from langchain_core.globals import set_llm_cache# use any embedding provider...from tests.integration_tests.vectorstores.fake_embeddings import FakeEmbeddingsmongodb_atlas_uri = "<YOUR_CONNECTION_STRING>"COLLECTION_NAME="<YOUR_CACHE_COLLECTION_NAME>"DATABASE_NAME="<YOUR_DATABASE_NAME>"set_llm_cache(MongoDBCache(    connection_string=mongodb_atlas_uri,    collection_name=COLLECTION_NAME,    database_name=DATABASE_NAME,))
```

**API Reference:**[set\_llm\_cache](https://python.langchain.com/api_reference/core/globals/langchain_core.globals.set_llm_cache.html)

### MongoDBAtlasSemanticCache

Semantic caching allows users to retrieve cached prompts based on semantic similarity between the user input and previously cached results. Under the hood it blends MongoDBAtlas as both a cache and a vectorstore. The MongoDBAtlasSemanticCache inherits from `MongoDBAtlasVectorSearch` and needs an Atlas Vector Search Index defined to work. Please look at the [usage example](/oss/integrations/vectorstores/mongodb_atlas) on how to set up the index.

To import this cache:

```
from langchain_mongodb.cache import MongoDBAtlasSemanticCache
```

**API Reference:**[MongoDBAtlasSemanticCache](https://python.langchain.com/api_reference/mongodb/cache/langchain_mongodb.cache.MongoDBAtlasSemanticCache.html)

To use this cache with your LLMs:

```
from langchain_core.globals import set_llm_cache# use any embedding provider...from tests.integration_tests.vectorstores.fake_embeddings import FakeEmbeddingsmongodb_atlas_uri = "<YOUR_CONNECTION_STRING>"COLLECTION_NAME="<YOUR_CACHE_COLLECTION_NAME>"DATABASE_NAME="<YOUR_DATABASE_NAME>"set_llm_cache(MongoDBAtlasSemanticCache(    embedding=FakeEmbeddings(),    connection_string=mongodb_atlas_uri,    collection_name=COLLECTION_NAME,    database_name=DATABASE_NAME,))
```

**API Reference:**[set\_llm\_cache](https://python.langchain.com/api_reference/core/globals/langchain_core.globals.set_llm_cache.html)
