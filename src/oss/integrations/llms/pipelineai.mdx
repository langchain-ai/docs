---
title: "PipelineAI"
---

> [PipelineAI](https://pipeline.ai) allows you to run your ML models at scale in the cloud. It also provides API access to [several LLM models](https://pipeline.ai).

This notebook goes over how to use Langchain with [PipelineAI](https://docs.pipeline.ai/docs).

## PipelineAI example

[This example shows how PipelineAI integrated with LangChain](https://docs.pipeline.ai/oss/langchain) and it is created by PipelineAI.

## Setup

The `pipeline-ai` library is required to use the `PipelineAI` API, AKA `Pipeline Cloud`. Install `pipeline-ai` using `pip install pipeline-ai`.

```
# Install the package%pip install --upgrade --quiet  pipeline-ai
```

## Example

### Imports

```
import osfrom langchain_community.llms import PipelineAIfrom langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import PromptTemplate
```

**API Reference:**[PipelineAI](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.pipelineai.PipelineAI.html) | [StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html)

### Set the Environment API Key

Make sure to get your API key from PipelineAI. Check out the [cloud quickstart guide](https://docs.pipeline.ai/oss/cloud-quickstart). You'll be given a 30 day free trial with 10 hours of serverless GPU compute to test different models.

```
os.environ["PIPELINE_API_KEY"] = "YOUR_API_KEY_HERE"
```

## Create the PipelineAI instance

When instantiating PipelineAI, you need to specify the id or tag of the pipeline you want to use, e.g. `pipeline_key = "public/gpt-j:base"`. You then have the option of passing additional pipeline-specific keyword arguments:

```
llm = PipelineAI(pipeline_key="YOUR_PIPELINE_KEY", pipeline_kwargs={...})
```

### Create a Prompt Template

We will create a prompt template for Question and Answer.

```
template = """Question: {question}Answer: Let's think step by step."""prompt = PromptTemplate.from_template(template)
```

### Initiate the LLMChain

```
llm_chain = prompt | llm | StrOutputParser()
```

### Run the LLMChain

Provide a question and run the LLMChain.

```
question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"llm_chain.invoke(question)
```

## Related

* LLM [conceptual guide](/oss/concepts/text_llms)
* LLM [how-to guides](/oss/how_to/#llms)
