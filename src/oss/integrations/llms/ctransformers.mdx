---
title: "C Transformers"
---

The [C Transformers](https://github.com/marella/ctransformers) library provides Python bindings for GGML models.

This example goes over how to use LangChain to interact with `C Transformers` [models](https://github.com/marella/ctransformers#supported-models).

**Install**

```
%pip install --upgrade --quiet  ctransformers
```

**Load Model**

```
from langchain_community.llms import CTransformersllm = CTransformers(model="marella/gpt-2-ggml")
```

**API Reference:**[CTransformers](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.ctransformers.CTransformers.html)

**Generate Text**

```
print(llm.invoke("AI is going to"))
```

**Streaming**

```
from langchain_core.callbacks import StreamingStdOutCallbackHandlerllm = CTransformers(    model="marella/gpt-2-ggml", callbacks=[StreamingStdOutCallbackHandler()])response = llm.invoke("AI is going to")
```

**API Reference:**[StreamingStdOutCallbackHandler](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler.html)

**LLMChain**

```
from langchain.chains import LLMChainfrom langchain_core.prompts import PromptTemplatetemplate = """Question: {question}Answer:"""prompt = PromptTemplate.from_template(template)llm_chain = LLMChain(prompt=prompt, llm=llm)response = llm_chain.run("What is AI?")
```

**API Reference:**[LLMChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.llm.LLMChain.html) | [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html)

## Related

* LLM [conceptual guide](/src/oss/concepts/text_llms)
* LLM [how-to guides](/src/oss/how_to/#llms)
