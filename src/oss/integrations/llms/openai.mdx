---
title: "OpenAI"
---

<Warning>
  You are currently on a page documenting the use of OpenAI [text completion models](/oss/concepts/text_llms). The latest and most popular OpenAI models are [chat completion models](/oss/concepts/chat_models).

  Unless you are specifically using `gpt-3.5-turbo-instruct`, you are probably looking for [this page instead](/oss/integrations/chat/openai).
</Warning>

[OpenAI](https://platform.openai.com/oss/introduction) offers a spectrum of models with different levels of power suitable for different tasks.

This example goes over how to use LangChain to interact with `OpenAI` [models](https://platform.openai.com/oss/models)

## Overview

### Integration details

| Class                                                                                                                         | Package                                                                          | Local | Serializable | [JS support](https://js.langchain.com/oss/integrations/chat/openai) | Package downloads                                                                   | Package latest                                                                   |
| ----------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | ----- | ------------ | -------------------------------------------------------------------- | ----------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain-openai](https://python.langchain.com/api_reference/openai/index.html) | ❌     | beta         | ✅                                                                    | ![PyPI - Downloads](/images/oss/integrations/llms/openai/pypi/dm/langchain-openai) | ![PyPI - Version](/images/oss/integrations/llms/openai/pypi/v/langchain-openai) |

## Setup

To access OpenAI models you'll need to create an OpenAI account, get an API key, and install the `langchain-openai` integration package.

### Credentials

Head to [https://platform.openai.com](https://platform.openai.com) to sign up to OpenAI and generate an API key. Once you've done this set the OPENAI\_API\_KEY environment variable:

```
import getpassimport osif "OPENAI_API_KEY" not in os.environ:    os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
```

To enable automated tracing of your model calls, set your [LangSmith](https://docs.smith.langchain.com/) API key:

```
# os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")# os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

The LangChain OpenAI integration lives in the `langchain-openai` package:

```
%pip install -qU langchain-openai
```

Should you need to specify your organization ID, you can use the following cell. However, it is not required if you are only part of a single organization or intend to use your default organization. You can check your default organization [here](https://platform.openai.com/account/api-keys).

To specify your organization, you can use this:

```
OPENAI_ORGANIZATION = getpass()os.environ["OPENAI_ORGANIZATION"] = OPENAI_ORGANIZATION
```

## Instantiation

Now we can instantiate our model object and generate chat completions:

```
from langchain_openai import OpenAIllm = OpenAI()
```

**API Reference:**[OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)

## Invocation

```
llm.invoke("Hello how are you?")
```

```
'\n\nI am an AI and do not have emotions like humans do, so I am always functioning at my optimal level. Thank you for asking! How can I assist you today?'
```

## Chaining

```
from langchain_core.prompts import PromptTemplateprompt = PromptTemplate.from_template("How to say {input} in {output_language}:\n")chain = prompt | llmchain.invoke(    {        "output_language": "German",        "input": "I love programming.",    })
```

**API Reference:**[PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html)

```
'\nIch liebe Programmieren.'
```

## Using a proxy

If you are behind an explicit proxy, you can specify the http\_client to pass through

```
%pip install httpximport httpxopenai = OpenAI(    model_name="gpt-3.5-turbo-instruct",    http_client=httpx.Client(proxies="http://proxy.yourcompany.com:8080"),)
```

## API reference

For detailed documentation of all `OpenAI` llm features and configurations head to the API reference: [https://python.langchain.com/api\_reference/openai/llms/langchain\_openai.llms.base.OpenAI.html](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)

## Related

* LLM [conceptual guide](/oss/concepts/text_llms)
* LLM [how-to guides](/oss/how_to/#llms)
