---
title: "Fireworks"
---

<Warning>
  You are currently on a page documenting the use of Fireworks models as [text completion models](/oss/concepts/text_llms). Many popular Fireworks models are [chat completion models](/oss/concepts/chat_models).

  You may be looking for [this page instead](/oss/integrations/chat/fireworks).
</Warning>

> [Fireworks](https://app.fireworks.ai/) accelerates product development on generative AI by creating an innovative AI experiment and production platform.

This example goes over how to use LangChain to interact with `Fireworks` models.

## Overview

### Integration details

| Class                                                                                                                                             | Package                                                                                 | Local | Serializable | [JS support](https://js.langchain.com/v0.1/oss/integrations/llms/fireworks/) | Package downloads                                                                         | Package latest                                                                         |
| ------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- | ----- | ------------ | ----------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| [Fireworks](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks) | [langchain\_fireworks](https://python.langchain.com/api_reference/fireworks/index.html) | ❌     | ❌            | ✅                                                                             | ![PyPI - Downloads](/images/oss/integrations/llms/fireworks/pypi/dm/langchain_fireworks) | ![PyPI - Version](/images/oss/integrations/llms/fireworks/pypi/v/langchain_fireworks) |

## Setup

### Credentials

Sign in to [Fireworks AI](http://fireworks.ai) for the an API Key to access our models, and make sure it is set as the `FIREWORKS_API_KEY` environment variable. 3. Set up your model using a model id. If the model is not set, the default model is fireworks-llama-v2-7b-chat. See the full, most up-to-date model list on [fireworks.ai](https://fireworks.ai).

```
import getpassimport osif "FIREWORKS_API_KEY" not in os.environ:    os.environ["FIREWORKS_API_KEY"] = getpass.getpass("Fireworks API Key:")
```

### Installation

You need to install the `langchain_fireworks` python package for the rest of the notebook to work.

```
%pip install -qU langchain-fireworks
```

```
Note: you may need to restart the kernel to use updated packages.
```

## Instantiation

```
from langchain_fireworks import Fireworks# Initialize a Fireworks modelllm = Fireworks(    model="accounts/fireworks/models/llama-v3p1-8b-instruct",    base_url="https://api.fireworks.ai/inference/v1/completions",)
```

**API Reference:**[Fireworks](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html)

## Invocation

You can call the model directly with string prompts to get completions.

```
output = llm.invoke("Who's the best quarterback in the NFL?")print(output)
```

```
 If Manningville Station, Lions rookie EJ Manuel's
```

### Invoking with multiple prompts

```
# Calling multiple promptsoutput = llm.generate(    [        "Who's the best cricket player in 2016?",        "Who's the best basketball player in the league?",    ])print(output.generations)
```

```
[[Generation(text=" We're not just asking, we've done some research. We'")], [Generation(text=' The conversation is dominated by Kobe Bryant, Dwyane Wade,')]]
```

### Invoking with additional parameters

```
# Setting additional parameters: temperature, max_tokens, top_pllm = Fireworks(    model="accounts/fireworks/models/llama-v3p1-8b-instruct",    temperature=0.7,    max_tokens=15,    top_p=1.0,)print(llm.invoke("What's the weather like in Kansas City in December?"))
```

```
December is a cold month in Kansas City, with temperatures of
```

## Chaining

You can use the LangChain Expression Language to create a simple chain with non-chat models.

```
from langchain_core.prompts import PromptTemplatefrom langchain_fireworks import Fireworksllm = Fireworks(    model="accounts/fireworks/models/llama-v3p1-8b-instruct",    temperature=0.7,    max_tokens=15,    top_p=1.0,)prompt = PromptTemplate.from_template("Tell me a joke about {topic}?")chain = prompt | llmprint(chain.invoke({"topic": "bears"}))
```

**API Reference:**[PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html) | [Fireworks](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html)

```
 What do you call a bear with no teeth? A gummy bear!
```

## Streaming

You can stream the output, if you want.

```
for token in chain.stream({"topic": "bears"}):    print(token, end="", flush=True)
```

```
 Why do bears hate shoes so much? They like to run around in their
```

## API reference

For detailed documentation of all `Fireworks` LLM features and configurations head to the API reference: [https://python.langchain.com/api\_reference/fireworks/llms/langchain\_fireworks.llms.Fireworks.html#langchain\_fireworks.llms.Fireworks](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks)

## Related

* LLM [conceptual guide](/oss/concepts/text_llms)
* LLM [how-to guides](/oss/how_to/#llms)
