---
title: "Overview"
---

<Warning>
  You are currently on a page documenting the use of [text completion models](/src/oss/concepts/text_llms). Many of the latest and most popular models are [chat completion models](/src/oss/concepts/chat_models).

  Unless you are specifically using more advanced prompting techniques, you are probably looking for [this page instead](/src/oss/integrations/chat).
</Warning>

[LLMs](/src/oss/concepts/text_llms) are language models that take a string as input and return a string as output.

<Info>
  If you'd like to write your own LLM, see [this how-to](/src/oss/how_to/custom_llm). If you'd like to contribute an integration, see [Contributing integrations](/src/oss/contributing/how_to/integrations).
</Info>

| Provider                       | Package                                                                                                                                   |
| ------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
| [AI21LLM](/src/oss/../ai21)                | [langchain-ai21](https://python.langchain.com/api_reference/ai21/llms/langchain_ai21.llms.AI21LLM.html)                                   |
| [AnthropicLLM](/src/oss/../anthropic)      | [langchain-anthropic](https://python.langchain.com/api_reference/anthropic/llms/langchain_anthropic.llms.AnthropicLLM.html)               |
| [AzureOpenAI](/src/oss/../azure_openai)    | [langchain-openai](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.azure.AzureOpenAI.html)                   |
| [BedrockLLM](/src/oss/../bedrock)          | [langchain-aws](https://python.langchain.com/api_reference/aws/llms/langchain_aws.llms.bedrock.BedrockLLM.html)                           |
| [CohereLLM](/src/oss/../cohere)            | [langchain-cohere](https://python.langchain.com/api_reference/cohere/llms/langchain_cohere.llms.Cohere.html)                              |
| [FireworksLLM](/src/oss/../fireworks)      | [langchain-fireworks](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html)                  |
| [OllamaLLM](/src/oss/../ollama)            | [langchain-ollama](https://python.langchain.com/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html)                           |
| [OpenAILLM](/src/oss/../openai)            | [langchain-openai](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)                         |
| [TogetherLLM](/src/oss/../together)        | [langchain-together](https://python.langchain.com/api_reference/together/llms/langchain_together.llms.Together.html)                      |
| [VertexAILLM](/src/oss/../google_vertexai) | [langchain-google-vertexai](https://python.langchain.com/api_reference/google_vertexai/llms/langchain_google_vertexai.llms.VertexAI.html) |
| [NVIDIA](/src/oss/../nvidia_ai_endpoints)  | [langchain-nvidia](https://python.langchain.com/api_reference/nvidia_ai_endpoints/llm/langchain_nvidia_ai_endpoints.llm.NVIDIA.html)      |

## All LLMs

| Name                                                                                                | Description                                                               |
| --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| [AI21 Labs](/src/oss/integrations/llms/ai21)                                                           | See this page for the updated ChatAI21 object.                            |
| [Aleph Alpha](/src/oss/integrations/llms/aleph_alpha)                                                  | The Luminous series is a family of large language models.                 |
| [Alibaba Cloud PAI EAS](/src/oss/integrations/llms/alibabacloud_pai_eas_endpoint)                      | Machine Learning Platform for AI of Alibaba Cloud is a machine learni...  |
| [Amazon API Gateway](/src/oss/integrations/llms/amazon_api_gateway)                                    | Amazon API Gateway is a fully managed service that makes it easy for ...  |
| [Anyscale](/src/oss/integrations/llms/anyscale)                                                        | Anyscale is a fully-managed Ray platform, on which you can build, dep...  |
| [Aphrodite Engine](/src/oss/integrations/llms/aphrodite)                                               | Aphrodite is the open-source large-scale inference engine designed to...  |
| [Arcee](/src/oss/integrations/llms/arcee)                                                              | This notebook demonstrates how to use the Arcee class for generating ...  |
| [Azure ML](/src/oss/integrations/llms/azure_ml)                                                        | Azure ML is a platform used to build, train, and deploy machine learn...  |
| [Azure OpenAI](/src/oss/integrations/llms/azure_openai)                                                | You are currently on a page documenting the use of Azure OpenAI text ...  |
| [Baichuan LLM](/src/oss/integrations/llms/baichuan)                                                    | Baichuan Inc. (https Efficiency, Health, and Happiness.                   |
| [Baidu Qianfan](/src/oss/integrations/llms/baidu_qianfan_endpoint)                                     | Baidu AI Cloud Qianfan Platform is a one-stop large model development...  |
| [Banana](/src/oss/integrations/llms/banana)                                                            | Banana is focused on building the machine learning infrastructure.        |
| [Baseten](/src/oss/integrations/llms/baseten)                                                          | Baseten is a Provider in the LangChain ecosystem that implements the ...  |
| [Beam](/src/oss/integrations/llms/beam)                                                                | Calls the Beam API wrapper to deploy and make subsequent calls to an ...  |
| [Bedrock](/src/oss/integrations/llms/bedrock)                                                          | You are currently on a page documenting the use of Amazon Bedrock mod...  |
| [Bittensor](/src/oss/integrations/llms/bittensor)                                                      | Bittensor is a mining network, similar to Bitcoin, that includes buil...  |
| [CerebriumAI](/src/oss/integrations/llms/cerebriumai)                                                  | Cerebrium is an AWS Sagemaker alternative. It also provides API acces...  |
| [ChatGLM](/src/oss/integrations/llms/chatglm)                                                          | ChatGLM-6B is an open bilingual language model based on General Langu...  |
| [Clarifai](/src/oss/integrations/llms/clarifai)                                                        | Clarifai is an AI Platform that provides the full AI lifecycle rangin...  |
| [Cloudflare Workers AI](/src/oss/integrations/llms/cloudflare_workersai)                               | Cloudflare AI documentation listed all generative text models availab...  |
| [Cohere](/src/oss/integrations/llms/cohere)                                                            | You are currently on a page documenting the use of Cohere models as t...  |
| [C Transformers](/src/oss/integrations/llms/ctransformers)                                             | The C Transformers library provides Python bindings for GGML models.      |
| [CTranslate2](/src/oss/integrations/llms/ctranslate2)                                                  | CTranslate2 is a C++ and Python library for efficient inference with ...  |
| [Databricks](/src/oss/integrations/llms/databricks)                                                    | Databricks Lakehouse Platform unifies data, analytics, and AI on one ...  |
| [DeepInfra](/src/oss/integrations/llms/deepinfra)                                                      | DeepInfra is a serverless inference as a service that provides access...  |
| [DeepSparse](/src/oss/integrations/llms/deepsparse)                                                    | This page covers how to use the DeepSparse inference runtime within L...  |
| [Eden AI](/src/oss/integrations/llms/edenai)                                                           | Eden AI is revolutionizing the AI landscape by uniting the best AI pr...  |
| [ExLlamaV2](/src/oss/integrations/llms/exllamav2)                                                      | ExLlamav2 is a fast inference library for running LLMs locally on mod...  |
| [Fireworks](/src/oss/integrations/llms/fireworks)                                                      | You are currently on a page documenting the use of Fireworks models a...  |
| [ForefrontAI](/src/oss/integrations/llms/forefrontai)                                                  | The Forefront platform gives you the ability to fine-tune and use ope...  |
| [Friendli](/src/oss/integrations/llms/friendli)                                                        | Friendli enhances AI application performance and optimizes cost savin...  |
| [Google AI](/src/oss/integrations/llms/google_ai)                                                      | You are currently on a page documenting the use of Google models as t...  |
| [Google Cloud Vertex AI](/src/oss/integrations/llms/google_vertex_ai_palm)                             | You are currently on a page documenting the use of Google Vertex text...  |
| [GooseAI](/src/oss/integrations/llms/gooseai)                                                          | GooseAI is a fully managed NLP-as-a-Service, delivered via API. Goose...  |
| [GPT4All](/src/oss/integrations/llms/gpt4all)                                                          | GitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained ...  |
| [Gradient](/src/oss/integrations/llms/gradient)                                                        | Gradient allows to fine tune and get completions on LLMs with a simpl...  |
| [Huggingface Endpoints](/src/oss/integrations/llms/huggingface_endpoint)                               | The Hugging Face Hub is a platform with over 120k models, 20k dataset...  |
| [Hugging Face Local Pipelines](/src/oss/integrations/llms/huggingface_pipelines)                       | Hugging Face models can be run locally through the HuggingFacePipelin...  |
| [IBM watsonx.ai](/src/oss/integrations/llms/ibm_watsonx)                                               | WatsonxLLM is a wrapper for IBM watsonx.ai foundation models.             |
| [IPEX-LLM](/src/oss/integrations/llms/ipex_llm)                                                        | IPEX-LLM is a PyTorch library for running LLM on Intel CPU and GPU (e...  |
| [Javelin AI Gateway Tutorial](/src/oss/integrations/llms/javelin)                                      | This Jupyter Notebook will explore how to interact with the Javelin A...  |
| [JSONFormer](/src/oss/integrations/llms/jsonformer_experimental)                                       | JSONFormer is a library that wraps local Hugging Face pipeline models...  |
| [KoboldAI API](/src/oss/integrations/llms/koboldai)                                                    | KoboldAI is a "a browser-based front-end for AI-assisted writing with...  |
| [Konko](/src/oss/integrations/llms/konko)                                                              | Konko API is a fully managed Web API designed to help application dev...  |
| [Layerup Security](/src/oss/integrations/llms/layerup_security)                                        | The Layerup Security integration allows you to secure your calls to a...  |
| [Llama.cpp](/src/oss/integrations/llms/llamacpp)                                                       | llama-cpp-python is a Python binding for llama.cpp.                       |
| [Llamafile](/src/oss/integrations/llms/llamafile)                                                      | Llamafile lets you distribute and run LLMs with a single file.            |
| [LM Format Enforcer](/src/oss/integrations/llms/lmformatenforcer_experimental)                         | LM Format Enforcer is a library that enforces the output format of la...  |
| [Manifest](/src/oss/integrations/llms/manifest)                                                        | This notebook goes over how to use Manifest and LangChain.                |
| [Minimax](/src/oss/integrations/llms/minimax)                                                          | Minimax is a Chinese startup that provides natural language processin...  |
| [MLX Local Pipelines](/src/oss/integrations/llms/mlx_pipelines)                                        | MLX models can be run locally through the MLXPipeline class.              |
| [Modal](/src/oss/integrations/llms/modal)                                                              | The Modal cloud platform provides convenient, on-demand access to ser...  |
| [ModelScope](/src/oss/integrations/llms/modelscope_endpoint)                                           | ModelScope (Home \| GitHub) is built upon the notion of â€œModel-as-a-Se... |
| [MoonshotChat](/src/oss/integrations/llms/moonshot)                                                    | Moonshot is a Chinese startup that provides LLM service for companies...  |
| [MosaicML](/src/oss/integrations/llms/mosaicml)                                                        | MosaicML offers a managed inference service. You can either use a var...  |
| [NLP Cloud](/src/oss/integrations/llms/nlpcloud)                                                       | The NLP Cloud serves high performance pre-trained or custom models fo...  |
| [NVIDIA](/src/oss/integrations/llms/nvidia_ai_endpoints)                                               | This will help you get started with NVIDIA models. For detailed docum...  |
| [oci\_generative\_ai](/src/oss/integrations/llms/oci_generative_ai)                                    | Oracle Cloud Infrastructure Generative AI                                 |
| [OCI Data Science Model Deployment Endpoint](/src/oss/integrations/llms/oci_model_deployment_endpoint) | OCI Data Science is a fully managed and serverless platform for data ...  |
| [OctoAI](/src/oss/integrations/llms/octoai)                                                            | OctoAI offers easy access to efficient compute and enables users to i...  |
| [Ollama](/src/oss/integrations/llms/ollama)                                                            | You are currently on a page documenting the use of Ollama models as t...  |
| [OpaquePrompts](/src/oss/integrations/llms/opaqueprompts)                                              | OpaquePrompts is a service that enables applications to leverage the ...  |
| [OpenAI](/src/oss/integrations/llms/openai)                                                            | You are currently on a page documenting the use of OpenAI text comple...  |
| [OpenLLM](/src/oss/integrations/llms/openllm)                                                          | ðŸ¦¾ OpenLLM lets developers run any open-source LLMs as OpenAI-compati...  |
| [OpenLM](/src/oss/integrations/llms/openlm)                                                            | OpenLM is a zero-dependency OpenAI-compatible LLM provider that can c...  |
| [OpenVINO](/src/oss/integrations/llms/openvino)                                                        | OpenVINOâ„¢ is an open-source toolkit for optimizing and deploying AI i...  |
| [Outlines](/src/oss/integrations/llms/outlines)                                                        | This will help you get started with Outlines LLM. For detailed docume...  |
| [Petals](/src/oss/integrations/llms/petals)                                                            | Petals runs 100B+ language models at home, BitTorrent-style.              |
| [PipelineAI](/src/oss/integrations/llms/pipelineai)                                                    | PipelineAI allows you to run your ML models at scale in the cloud. It...  |
| [Pipeshift](/src/oss/integrations/llms/pipeshift)                                                      | This will help you get started with Pipeshift completion models (LLMs...  |
| [Predibase](/src/oss/integrations/llms/predibase)                                                      | Predibase allows you to train, fine-tune, and deploy any ML modelâ€”fro...  |
| [PredictionGuard](/src/oss/integrations/llms/predictionguard)                                          | Prediction Guard is a secure, scalable GenAI platform that safeguards...  |
| [PromptLayer OpenAI](/src/oss/integrations/llms/promptlayer_openai)                                    | PromptLayer is the first platform that allows you to track, manage, a...  |
| [RELLM](/src/oss/integrations/llms/rellm_experimental)                                                 | RELLM is a library that wraps local Hugging Face pipeline models for ...  |
| [Replicate](/src/oss/integrations/llms/replicate)                                                      | Replicate runs machine learning models in the cloud. We have a librar...  |
| [Runhouse](/src/oss/integrations/llms/runhouse)                                                        | Runhouse allows remote compute and data across environments and users...  |
| [RunPod LLM](/src/oss/integrations/llms/runpod)                                                        | Get started with RunPod LLMs.                                             |
| [SageMakerEndpoint](/src/oss/integrations/llms/sagemaker)                                              | Amazon SageMaker is a system that can build, train, and deploy machin...  |
| [SambaNovaCloud](/src/oss/integrations/llms/sambanovacloud)                                            | SambaNova's SambaNova Cloud is a platform for performing inference wi...  |
| [SambaStudio](/src/oss/integrations/llms/sambastudio)                                                  | SambaNova's Sambastudio is a platform that allows you to train, run b...  |
| [Solar](/src/oss/integrations/llms/solar)                                                              | This community integration is deprecated. You should use ChatUpstage ...  |
| [SparkLLM](/src/oss/integrations/llms/sparkllm)                                                        | SparkLLM is a large-scale cognitive model independently developed by ...  |
| [StochasticAI](/src/oss/integrations/llms/stochasticai)                                                | Stochastic Acceleration Platform aims to simplify the life cycle of a...  |
| [Nebula (Symbl.ai)](/src/oss/integrations/llms/symblai_nebula)                                         | Nebula is a large language model (LLM) built by Symbl.ai. It is train...  |
| [TextGen](/src/oss/integrations/llms/textgen)                                                          | GitHub:oobabooga/text-generation-webui A gradio web UI for running La...  |
| [Titan Takeoff](/src/oss/integrations/llms/titan_takeoff)                                              | TitanML helps businesses build and deploy better, smaller, cheaper, a...  |
| [Together AI](/src/oss/integrations/llms/together)                                                     | You are currently on a page documenting the use of Together AI models...  |
| [Tongyi Qwen](/src/oss/integrations/llms/tongyi)                                                       | Tongyi Qwen is a large-scale language model developed by Alibaba's Da...  |
| [vLLM](/src/oss/integrations/llms/vllm)                                                                | vLLM is a fast and easy-to-use library for LLM inference and serving,...  |
| [Volc Engine Maas](/src/oss/integrations/llms/volcengine_maas)                                         | This notebook provides you with a guide on how to get started with Vo...  |
| [Intel Weight-Only Quantization](/src/oss/integrations/llms/weight_only_quantization)                  | Weight-Only Quantization for Huggingface Models with Intel Extension ...  |
| [Writer LLM](/src/oss/integrations/llms/writer)                                                        | Writer is a platform to generate different language content.              |
| [Xorbits Inference (Xinference)](/src/oss/integrations/llms/xinference)                                | Xinference is a powerful and versatile library designed to serve LLMs,    |
| [YandexGPT](/src/oss/integrations/llms/yandex)                                                         | This notebook goes over how to use Langchain with YandexGPT.              |
| [Yi](/src/oss/integrations/llms/yi)                                                                    | 01.AI, founded by Dr. Kai-Fu Lee, is a global company at the forefron...  |
| [Yuan2.0](/src/oss/integrations/llms/yuan2)                                                            | Yuan2.0 is a new generation Fundamental Large Language Model develope...  |
