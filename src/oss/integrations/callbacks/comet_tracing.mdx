---
title: "Comet Tracing"
---

There are two ways to trace your LangChains executions with Comet:

1. Setting the `LANGCHAIN_COMET_TRACING` environment variable to "true". This is the recommended way.
2. Import the `CometTracer` manually and pass it explicitely.

```
import osimport comet_llmfrom langchain_openai import OpenAIos.environ["LANGCHAIN_COMET_TRACING"] = "true"# Connect to Comet if no API Key is setcomet_llm.init()# comet documentation to configure comet using env variables# https://www.comet.com/oss/v2/api-and-sdk/llm-sdk/configuration/# here we are configuring the comet projectos.environ["COMET_PROJECT_NAME"] = "comet-example-langchain-tracing"from langchain.agents import AgentType, initialize_agent, load_tools
```

**API Reference:**[OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html) | [AgentType](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html) | [initialize\_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.initialize.initialize_agent.html) | [load\_tools](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.load_tools.load_tools.html)

```
# Agent run with tracing. Ensure that OPENAI_API_KEY is set appropriately to run this example.llm = OpenAI(temperature=0)tools = load_tools(["llm-math"], llm=llm)
```

```
agent = initialize_agent(    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)agent.run("What is 2 raised to .123243 power?")  # this should be traced# An url for the chain like the following should print in your console:# https://www.comet.com/<workspace>/<project_name># The url can be used to view the LLM chain in Comet.
```

```
# Now, we unset the environment variable and use a context manager.if "LANGCHAIN_COMET_TRACING" in os.environ:    del os.environ["LANGCHAIN_COMET_TRACING"]from langchain_community.callbacks.tracers.comet import CometTracertracer = CometTracer()# Recreate the LLM, tools and agent and passing the callback to each of themllm = OpenAI(temperature=0)tools = load_tools(["llm-math"], llm=llm)agent = initialize_agent(    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)agent.run(    "What is 2 raised to .123243 power?", callbacks=[tracer])  # this should be traced
```

**API Reference:**[CometTracer](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.tracers.comet.CometTracer.html)
